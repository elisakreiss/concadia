

# Concadia: Towards Image-Based Text Generation with a Purpose

This is the official Github repository for our paper [Concadia: Towards Image-Based Text Generation with a Purpose](https://arxiv.org/abs/2104.08376). We provide the code and data necessary to replicate our results, as well as complimentary analyses.

## The CONCADIA dataset -- a dataset of CONtextualized images with Captions and Alt Descriptions from WikipedIA

Concadia is a dataset introduced in our paper and contains Wikipedia images with their respective captions, alt descriptions and the broader context the images are situated in. We use this corpus to argue for a clear distinction between descriptions and captions, and show the similarities and differences between the two text forms. We further argue that captions and broader context are an important resource that can inform the generation of descriptions which are very sparse across the Web but absolutely crucial to make images accessible.

For more details, including how to download Concadia, navigate to [Concadia_dataset/](Concadia_dataset).

## Reproducing Section 4: Model Experiments

Please navigate to [models/](models/) for more details
